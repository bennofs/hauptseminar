* introduction
** a lot of work on program tuning (selecting optimizations and/or parameters)
** also some work on analysing source code directly
** but what about inferring source code properties (program analysis) from dynamic features (gathered at runtime)?
** provides a principled way to incorporate ML in an explainable way
** runtime data is often huge, so good application of ML
* Program Analysis
** infer sound semantic properties from programs
** required for verification or optimization
** can be static or dynamic
* Learning with Dynamic Features
* Combined Dynamic/Static Features
* notes
* literature
:PROPERTIES:
:CATEGORY: hauptseminar-papers
:END:
** DONE Learning Nonlinear Loop Invariants with Gated Continous Logic Networks :dynamic:model:
Verifying real-world programs often requires inferring loop
invariants with nonlinear constraints. This is especially true
in programs that perform many numerical operations, such
as control systems for avionics or industrial plants. Recently,
data-driven methods for loop invariant inference have shown
promise, especially on linear loop invariants. However, ap-
plying data-driven inference to nonlinear loop invariants is
challenging due to the large numbers of and large magni-
tudes of high-order terms, the potential for overfitting on
a small number of samples, and the large space of possible
nonlinear inequality bounds.

In this paper, we introduce a new neural architecture for
general SMT learning, the Gated Continuous Logic Network
(G-CLN), and apply it to nonlinear loop invariant learning.
G-CLNs extend the Continuous Logic Network (CLN) archi-
tecture with gating units and dropout, which allow the model
to robustly learn general invariants over large numbers of
terms. To address overfitting that arises from finite program
sampling, we introduce fractional sampling—a sound relax-
ation of loop semantics to continuous functions that facili-
tates unbounded sampling on the real domain. We addition-
ally design a new CLN activation function, the Piecewise
Biased Quadratic Unit (PBQU), for naturally learning tight
inequality bounds.

We incorporate these methods into a nonlinear loop in-
variant inference system that can learn general nonlinear
loop invariants. We evaluate our system on a benchmark of
nonlinear loop invariants and show it solves 26 out of 27
problems, 3 more than prior work, with an average runtime
of 53.3 seconds. We further demonstrate the generic learning
ability of G-CLNs by solving all 124 problems in the linear
Code2Inv benchmark. We also perform a quantitative stabil-
ity evaluation and show G-CLNs have a convergence rate
of 97.5% on quadratic problems, a 39.2% improvement over
CLN models.
*** motivation: program verification requires loop invariants
*** research area: loop invariant inference using data-driven methods
*** method
**** use ML technologies (blackbox optimization) to fit a GCLN to runtime data of loops
**** basic idea: train a "network" that automatically learns which terms are important
**** derive loop invariants from "learned" parameters
**** use SMT checker to verify (since not all learned invariants are valid)
*** comparision to previous works
**** more general: can be applied to arbitrary non-linear invariants
**** does not require templates
*** fractional sampling
** CLN2INV: Learning Loop Invariants with Continuous Logic Networks
Program verification offers a framework for ensuring program correctness and
therefore systematically eliminating different classes of bugs.
Inferring loop invariants is one of the main challenges behind automated verification
of real-world programs, which often contain many loops.

In this paper, we present the Continuous Logic Network (CLN),
a novel neural architecture for automatically learning loop invariants
directly from program execution traces. Unlike existing neural networks,
CLNs can learn precise and explicit representations of formulas in
Satisfiability Modulo Theories (SMT) for loop invariants from program execution traces.
We develop a new sound and complete semantic mapping for assigning SMT formulas
to continuous truth values that allows CLNs to be trained efficiently.

We use CLNs to implement a new inference system for loop invariants, CLN2INV, that
significantly outperforms existing approaches on the popular Code2Inv dataset.
CLN2INV is the first tool to solve all 124 theoretically solvable problems in the
Code2Inv dataset. Moreover, CLN2INV takes only 1.1 second on average for each
problem, which is 40× faster than existing approaches. We further demonstrate
that CLN2INV can even learn 12 significantly more complex loop invariants than
the ones required for the Code2Inv dataset.
** DONE ML in compiler optimization :tuning:survey:
In the last decade, machine-learning-based
compilation has moved from an obscure research niche to a
mainstream activity.

In this paper, we describe the relationship
between machine learning and compiler optimization and
introduce the main concepts of features, models, training,
and deployment.

We then provide a comprehensive survey and provide a road map
for the wide variety of different research areas.
We conclude with a discussion on open issues in the area
and potential research directions.

This paper provides both an accessible introduction
to the fast moving area of machine-learning-based compilation
and a detailed bibliography of its main achievements.
*** describes models, feature engineering, applications and future directions
*** most usages seem to be focused on "tuning": tweaking the order or parameters of existing optimizations
*** not much references to work on program analysis for optimization using ML
** DONE A Survey of Machine Learning for Big Code and Naturalness :source:survey:
Research at the intersection of machine learning, programming languages,
and software engineering has recently taken important steps
in proposing learnable probabilistic models of source code
that exploit the abundance of patterns of code.

In this article, we survey this work. We contrast programming languages
against natural languages and discuss how these similarities and differences
drive the design of probabilistic models.

We present a taxonomy based on the underlying design principles of each model
and use it to navigate the literature. Then, we review how researchers have
adapted these models to application areas and discuss cross-cutting and
application-specific challenges and opportunities.
*** focused on Source Code as input (not dynamic features)
*** different kinds of models: code-generating models, representation models, pattern mining models
*** representation models seem interesting
*** program analysis references:
8 Learning to represent Programs with graphs
31 Learning Shape Analysis
38 Automatically generating features for learning program analysis heuristics for C-like languages
93 Using web corpus statistics for program analysis
106 Learning a classifier for false positive error reports emitted by static code analysis tools
115 Garted Graph Sequence Neural Networks
127 [[A User-Guided Approach to Program Analysis]]
147 Learning a strategy for adapting a program analysis via a Bayesian optimization
157 Deep Learning to find bugs
165 Predicting program properties from big code
** A User-Guided Approach to Program Analysis
Program analysis tools often produce undesirable output
due to various approximations. We present an approach
and a system Eugene that allows user feedback to guide
such approximations towards producing the desired output.
We formulate the problem of user-guided program analy-
sis in terms of solving a combination of hard rules and soft
rules: hard rules capture soundness while soft rules capture
degrees of approximations and preferences of users. Our
technique solves the rules using an off-the-shelf solver in a
manner that is sound (satisfies all hard rules), optimal (max-
imally satisfies soft rules), and scales to real-world analy-
ses and programs. We evaluate Eugene on two different
analyses with labeled output on a suite of seven Java pro-
grams of size 131–198 KLOC. We also report upon a user
study involving nine users who employ Eugene to guide an
information-flow analysis on three Java micro-benchmarks.
In our experiments, Eugene significantly reduces misclassi-
fied reports upon providing limited amounts of feedback.
** Probabilistic model for code with decision trees
In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).

The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy.

Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy.
** ALIVE-INFER: Data-Driven Precondition Inference for Peephole Optimizations in LLVM
Peephole optimizations are a common source of compiler
bugs. Compiler developers typically transform an incorrect
peephole optimization into a valid one by strengthening the
precondition. This process is challenging and tedious. This
paper proposes A LIVE -I NFER , a data-driven approach that
infers preconditions for peephole optimizations expressed
in Alive. A LIVE -I NFER generates positive and negative
examples for an optimization, enumerates predicates on-
demand, and learns a set of predicates that separate the
positive and negative examples. A LIVE -I NFER repeats this
process until it finds a precondition that ensures the validity
of the optimization. A LIVE -I NFER reports both a weakest
precondition and a set of succinct partial preconditions to
the developer. Our prototype generates preconditions that are
weaker than LLVM’s preconditions for 73 optimizations in
the Alive suite. We also demonstrate the applicability of this
technique to generalize 54 optimization patterns generated
by Souper, an LLVM IR–based superoptimizer.
