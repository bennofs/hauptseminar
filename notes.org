* introduction
** traditionally: image of compiler as batch process, where correctness is of highest importance
** but: heuristics for optimization often ad-hoc
** but: programs have bugs, a correct compiler won't help there => heuristics for warnings
** => use ML for better foundation of heuristics based on realworld data
** also: new possibilities (code recommendation, clone detection based on semantic similarity)

** here: derive semantic representation from code ("understanding"), general architecture
** high level: focus on structure, not on detailed ML implementation
* outline
** first, brief look at how different models work
** second, evaluation of those models
** third, future research directions
** last, conclusion
* programs as languages
central question: how to input source code into models
one answer given by Allamanis et al via the naturalness hypothesis:

#+BEGIN_QUOTE
*The naturalness hypothesis*

Software is a form of human communication;
software corpora have similar statistical properties to natural language corpora;
and these properties can be exploited to build better software engineering tools.
#+END_QUOTE

=> use NLP methods
* more structure: ast paths
** code2vec, code2seq
* from paths to graphs
** CRF (Raychev et al)
** GGNN (Allamanis et al, Cummins et al)
* a different angle: using runtime data
** API path mining (multiple)
** Loop approximation (Yao et al)
** Dypro, Liger (Wang et al)
* evaluation: tasks
hard to compare different models because they focus on different tasks
(BACKUP: table with models and tasks)

** method name prediction
** loop invariant generation
* research directions
** understand *how*/*what* models learn
*** are some models better for some tasks?
*** dependence on language features?
*** do adversarial examples differ?
*** a unified benchmark/task set would be nice (COSET is unfortunately not public yet)
** new architectures
*** general pretrained models that can be finetuned? (cf BERT, GPT, XLNet)
*** combine dynamic with static features?
* conclusion
** active research in structured models
** lots of open questions
** more data would enable better evaluation (how about a google recaptcha for algorithms?)
** but still, many cool applications (maybe too many?)
* literature
:PROPERTIES:
:CATEGORY: hauptseminar-papers
:END:
** DONE Learning Nonlinear Loop Invariants with Gated Continous Logic Networks :dynamic:model:
Verifying real-world programs often requires inferring loop
invariants with nonlinear constraints. This is especially true
in programs that perform many numerical operations, such
as control systems for avionics or industrial plants. Recently,
data-driven methods for loop invariant inference have shown
promise, especially on linear loop invariants. However, ap-
plying data-driven inference to nonlinear loop invariants is
challenging due to the large numbers of and large magni-
tudes of high-order terms, the potential for overfitting on
a small number of samples, and the large space of possible
nonlinear inequality bounds.

In this paper, we introduce a new neural architecture for
general SMT learning, the Gated Continuous Logic Network
(G-CLN), and apply it to nonlinear loop invariant learning.
G-CLNs extend the Continuous Logic Network (CLN) archi-
tecture with gating units and dropout, which allow the model
to robustly learn general invariants over large numbers of
terms. To address overfitting that arises from finite program
sampling, we introduce fractional sampling—a sound relax-
ation of loop semantics to continuous functions that facili-
tates unbounded sampling on the real domain. We addition-
ally design a new CLN activation function, the Piecewise
Biased Quadratic Unit (PBQU), for naturally learning tight
inequality bounds.

We incorporate these methods into a nonlinear loop in-
variant inference system that can learn general nonlinear
loop invariants. We evaluate our system on a benchmark of
nonlinear loop invariants and show it solves 26 out of 27
problems, 3 more than prior work, with an average runtime
of 53.3 seconds. We further demonstrate the generic learning
ability of G-CLNs by solving all 124 problems in the linear
Code2Inv benchmark. We also perform a quantitative stabil-
ity evaluation and show G-CLNs have a convergence rate
of 97.5% on quadratic problems, a 39.2% improvement over
CLN models.
*** motivation: program verification requires loop invariants
*** research area: loop invariant inference using data-driven methods
*** method
**** use ML technologies (blackbox optimization) to fit a GCLN to runtime data of loops
**** basic idea: train a "network" that automatically learns which terms are important
**** derive loop invariants from "learned" parameters
**** use SMT checker to verify (since not all learned invariants are valid)
*** comparision to previous works
**** more general: can be applied to arbitrary non-linear invariants
**** does not require templates
*** fractional sampling
** CLN2INV: Learning Loop Invariants with Continuous Logic Networks
Program verification offers a framework for ensuring program correctness and
therefore systematically eliminating different classes of bugs.
Inferring loop invariants is one of the main challenges behind automated verification
of real-world programs, which often contain many loops.

In this paper, we present the Continuous Logic Network (CLN),
a novel neural architecture for automatically learning loop invariants
directly from program execution traces. Unlike existing neural networks,
CLNs can learn precise and explicit representations of formulas in
Satisfiability Modulo Theories (SMT) for loop invariants from program execution traces.
We develop a new sound and complete semantic mapping for assigning SMT formulas
to continuous truth values that allows CLNs to be trained efficiently.

We use CLNs to implement a new inference system for loop invariants, CLN2INV, that
significantly outperforms existing approaches on the popular Code2Inv dataset.
CLN2INV is the first tool to solve all 124 theoretically solvable problems in the
Code2Inv dataset. Moreover, CLN2INV takes only 1.1 second on average for each
problem, which is 40× faster than existing approaches. We further demonstrate
that CLN2INV can even learn 12 significantly more complex loop invariants than
the ones required for the Code2Inv dataset.
** DONE ML in compiler optimization :tuning:survey:
In the last decade, machine-learning-based
compilation has moved from an obscure research niche to a
mainstream activity.

In this paper, we describe the relationship
between machine learning and compiler optimization and
introduce the main concepts of features, models, training,
and deployment.

We then provide a comprehensive survey and provide a road map
for the wide variety of different research areas.
We conclude with a discussion on open issues in the area
and potential research directions.

This paper provides both an accessible introduction
to the fast moving area of machine-learning-based compilation
and a detailed bibliography of its main achievements.
*** describes models, feature engineering, applications and future directions
*** most usages seem to be focused on "tuning": tweaking the order or parameters of existing optimizations
*** not much references to work on program analysis for optimization using ML
** DONE A Survey of Machine Learning for Big Code and Naturalness :source:survey:
Research at the intersection of machine learning, programming languages,
and software engineering has recently taken important steps
in proposing learnable probabilistic models of source code
that exploit the abundance of patterns of code.

In this article, we survey this work. We contrast programming languages
against natural languages and discuss how these similarities and differences
drive the design of probabilistic models.

We present a taxonomy based on the underlying design principles of each model
and use it to navigate the literature. Then, we review how researchers have
adapted these models to application areas and discuss cross-cutting and
application-specific challenges and opportunities.
*** focused on Source Code as input (not dynamic features)
*** different kinds of models: code-generating models, representation models, pattern mining models
*** representation models seem interesting
*** program analysis references:
8 Learning to represent Programs with graphs
31 Learning Shape Analysis
38 Automatically generating features for learning program analysis heuristics for C-like languages
93 Using web corpus statistics for program analysis
106 Learning a classifier for false positive error reports emitted by static code analysis tools
115 Gated Graph Sequence Neural Networks
127 [[A User-Guided Approach to Program Analysis]]
147 Learning a strategy for adapting a program analysis via a Bayesian optimization
157 Deep Learning to find bugs
165 Predicting program properties from big code
** A User-Guided Approach to Program Analysis
Program analysis tools often produce undesirable output
due to various approximations. We present an approach
and a system Eugene that allows user feedback to guide
such approximations towards producing the desired output.
We formulate the problem of user-guided program analy-
sis in terms of solving a combination of hard rules and soft
rules: hard rules capture soundness while soft rules capture
degrees of approximations and preferences of users. Our
technique solves the rules using an off-the-shelf solver in a
manner that is sound (satisfies all hard rules), optimal (max-
imally satisfies soft rules), and scales to real-world analy-
ses and programs. We evaluate Eugene on two different
analyses with labeled output on a suite of seven Java pro-
grams of size 131–198 KLOC. We also report upon a user
study involving nine users who employ Eugene to guide an
information-flow analysis on three Java micro-benchmarks.
In our experiments, Eugene significantly reduces misclassi-
fied reports upon providing limited amounts of feedback.
** Probabilistic model for code with decision trees
In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).

The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy.

Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy.
** DONE [[file:ref.bib::menendez17_alive_infer][Menendez & Nagarakatte 2017: Alive-Infer: data-driven precondition inference for peephole optimizations in LLVM]]
Peephole optimizations are a common source of compiler bugs.
Compiler developers typically transform an incorrect peephole optimization into a valid one by strengthening the precondition.
This process is challenging and tedious.

This paper proposes Alive-Infer, a data-driven approach that infers preconditions for peephole optimizations expressed in Alive.
Alive-Infer generates positive and negative examples for an optimization, enumerates predicates on-demand,
and learns a set of predicates that separate the positive and negative examples.
Alive-Infer repeats this process until it finds a precondition that ensures the validity of the optimization.
Alive-Infer reports both a weakest precondition and a set of succinct partial preconditions to the developer.

Our prototype generates preconditions that are weaker than LLVM’s preconditions for 73 optimizations in the Alive suite.
We also demonstrate the applicability of this technique to generalize 54 optimization patterns generated by Souper, an LLVM IR–based superoptimizer.
*** application of PIE to llvm with some real-world engineering challenges
** [[file:ref.bib::Raychev_2019][Raychev et al. 2019: Predicting program properties from “big code”]] :static:graph:
We present a new approach for predicting program properties from large codebases (aka "Big Code"). Our approach learns a probabilistic model from "Big Code" and uses this model to predict properties of new, unseen programs.

The key idea of our work is to transform the program into a representation that allows us to formulate the problem of inferring program properties as structured prediction in machine learning. This enables us to leverage powerful probabilistic models such as Conditional Random Fields (CRFs) and perform joint prediction of program properties.

As an example of our approach, we built a scalable prediction engine called jsnice for solving two kinds of tasks in the context of JavaScript: predicting (syntactic) names of identifiers and predicting (semantic) type annotations of variables. Experimentally, JSNICE predicts correct names for 63% of name identifiers and its type annotation predictions are correct in 81% of cases. Since its public release at http://jsnice.org, JSNice has become a popular system with hundreds of thousands of uses.

By formulating the problem of inferring program properties as structured prediction, our work opens up the possibility for a range of new "Big Code" applications such as de-obfuscators, decompilers, invariant generators, and others.
*** using conditional random fields
*** represent program as inference network
** [[file:ref.bib::bielik2020adversarial][Bielik & Vechev 2020: Adversarial Robustness for Code]]
*** abstract
Neural models of code have shown impressive performance for tasks such as predicting method names and identifying certain kinds of bugs.
In this paper, we show that these models are vulnerable to adversarial examples, and introduce a novel approach for attacking trained models of code with adversarial examples.
The main idea is to force a given trained model to make an incorrect prediction as specified by the adversary by introducing small perturbations that do not change the program’s semantics.
To find such perturbations, we present a new technique for Discrete Adversarial Manipulation of Programs (DAMP).
DAMP works by deriving the desired prediction with respect to the model’s inp uts while holding the model weights constant, and following the gradients to slightly modify the input code.

We show that our DAMP attack is effective across three neural architectures: code2vec, GGNN, and GNN-FiLM, in both Java and C#.
We show that DAMP has up to 89% success rate in changing a prediction to the adversary’s choice (“targeted attack”),
and a success rate of up to 94% in changing a given prediction to any incorrect prediction (“non-targeted attack”).
To defend a model against such attacks, we examine a variety of possible defenses empirically and discuss their trade-offs.
We show that some of these defenses drop the success rate of the attacker drastically, with a minor penalty of 2% relative degradation in accuracy while not performing under attack.
*** two mutations: variable renaming (single var) or inserting a new, unused variable statement
*** code2vec: non-targeted robustness only 6%, targeted 10.39% - 97.89%, can achieve ~90% F1 without var names
*** ggnn and gnn-film: higher robustness (57%-87.62%), where gnn-film > ggnn
*** also describe defense
*** interesting: transferability of adversarial samples
**** "We also did not find significant evidence that adversarial examples transfer across models that were trained on the same dataset, e.g., from GNN-FiLM to GGNN. "
**** "Occasionally, a dead code attack is transferable across example – it has the same effect even in different examples. This is demonstrated in Figure 10: adding the unused variable declaration int introsorter = 0;"
** [[file:ref.bib::ramakrishnan20:_seman_robus_model_sourc_code][Ramakrishnan et al. 2020: Semantic Robustness Models Source Code]]
*** abstract
Deep neural networks are vulnerable to adversarial examples - small input perturbations that result in incorrect predictions.
We study this problem for models of source code, where we want the network to be robust to source-code modifications that preserve code functionality.
(1) We define a powerful adversary that can employ sequences of parametric, semantics-preserving program transformations;
(2) we show how to perform adversarial training to learn models robust to such adversaries;
(3) we conduct an evaluation on different languages and architectures, demonstrating significant quantitative gains in robustness.
*** concept of k-robustness, define program transformations with holes which are then gradient optimized (as in bielik et al)
*** adversarial training improves robustness more for seq2seq than for code2seq => maybe code2seq already includes certain "robustness" by modeling assumption?
*** seq2seq can be better than code2seq in adversarial setting
** [[file:ref.bib::DBLP:conf/sigsoft/HenkelLLR18][Henkel et al. 2018: Code vectors]] :dynamic:symbolic:
*** abstract
With the rise of machine learning, there is a great deal of interest in treating programs as data to be fed to learning algorithms. However, programs do not start off in a form that is immediately amenable to most off-the-shelf learning techniques. Instead, it is necessary to transform the program to a suitable representation before a learning technique can be applied. In this paper, we use abstractions of traces obtained from symbolic execution of a program as a representation for learning word embeddings. We trained a variety of word embeddings under hundreds of parameterizations, and evaluated each learned embedding on a suite of different tasks. In our evaluation, we obtain 93% top-1 accuracy on a benchmark consisting of over 19,000 API-usage analogies extracted from the Linux kernel. In addition, we show that embeddings learned from (mainly) semantic abstractions provide nearly triple the accuracy of those learned from (mainly) syntactic abstractions.
*** abstract symbolic traces and learn a word2vec like embedding
*** evaluation focuses on functions that are related in usage patterns (analogies)
*** analogy examples: alloc/free, lock/unlock, store16/store32
*** traces are biased towards start of function (if we think of function as tree)
*** dataflow appears to be quite important
*** study error code prediction, but evaluation poor (only accuracy, top3, no statistical baseline)
*** encodes "behaviour" of function with respect to how they are called, not how they are implemented
** TODO [[file:ref.bib::DBLP:conf/nips/Ben-NunJH18][Ben-Nun et al. 2018: Neural Code Comprehension]]
*** abstract
With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.
