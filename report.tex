\documentclass[sigconf,authordraft=true,nonacm=true]{acmart}

\usepackage{polyglossia}
\usepackage{fontspec}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{makecell}
\usepackage{placeins}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{subcaption}

\setdefaultlanguage{english}
\usepackage{cleveref}

\newcommand{\etal}{\hbox{\emph{et al.}}\xspace}
\renewcommand{\cellalign}{l}

\begin{document}

\title{Graph- and behaviour-based machine learning models to understand program semantics}
\author{Benno Fünfstück}
\email{benno.fuenfstueck@tu-dresden.de}

\begin{abstract}
  Applying machine learning to detect patterns in programs requires finding a suitable form to input these programs into models.
  In this work, we look into two recently explored directions which do not require manually feature engineering: using the graph structure of programs and using execution traces.
  Both representations are proposed for different reasons: graph-based models can capture the syntatical properties of programs well and perform simple reasoning on them, while execution trace models are closer to program semantics.
  We explain applications of both models and then compare them on a set of tasks.
  We find that although both models are used for similar applications, different datasets make it hard to compare them.
  More research is needed to better explain the strengths of each model.
\end{abstract}

\maketitle

\section{Introduction}
Many tools that operate on source code require a form of program analysis.
This includes compilers needing to understand program semantics for optimization,
static analyzers designed to prevent bugs in programs
or development environments suggesting code completions and improvements.
Traditionally program analysis relies on abstraction, since finding an exact solution to the underlying problems is often computationally infeasible or even impossible.

But with the availability of large open source code repositories such as GitHub\footnote{https://github.com}, a new form of program analysis based on methods from machine learning is possible.
The fundamental principle of this form of program analysis is captured by the following hypothesis, the natural code hypothesis, as stated by \citet{allamanis_survey_2018}:
\begin{quote}
Software is a form of human communication;
software corpora have similar statistical properties to natural language corpora;
and these properties can be exploited to build better software engineering tools.
\end{quote}
For example, identifier names are not choosen randomly, but instead based on the meaning of the variable and therefore convey useful information for analysis.
This suggests using machine learning models for code.

A straightforward method then is to take models that have proven successful in natural language processing and apply them to source code.
Various applications of this pattern have been described in the literature \cite{ahmad_transformer-based_2020,malik_nl2type_2019,alon_code2vec_2019,hellendoorn_are_2017}.
The advantage of this method is that models working on sequences are well understood.
Additionally, since the order of tokens is preserved, the models can also learn from that information.
But the disadvantage is that these models generally are not well suited to deal with long-range dependencies such as those found when referring to variables and other structures that might be far away in the token representation of source code.

For this reason, new variants of representing programs as input to machine learning models have been explored.
Here, we will focus on two variants: graph-based models that rely on the graph structure of source code and behaviour-based models that make use of the executability of source code to find patterns in data gathered from execution traces.
First, we give a description of both models and its application to computer programs.
Then, we compare them on two tasks (method naming/classification and invariant inference).
We finish we a conclusion summarizing the results and listing some interesting future research directions.

\section{Graph-based model}
Graphs are a natural representation for source code, due to its highly interlinked structure.
In this section, we will thus look at models that can learn from the graph structure.
A flexible model for this task is the message passing neural network, introduced by \citet{gilmer_neural_2017}.
Message passing neural networks are a variant of graph neural networks.
We will first explain the general concept of message passing neural networks in \cref{sec:mpnn}.
We then compare different concrete instances of this model applied to source code in \cref{sec:app}.

Message passing neural networks are not the only kind of model that uses the graph structure for learning.
One alternative is described by \citet{raychev_predicting_2019} where they use conditional random fields to predict types and names of JavaScript variables.
Program elements are represented as nodes in a graph with edges between them capturing dependencies in their properties.
The probabilitistic weight of the dependency can then be learned from data, and the model be used to predict the unknown properties from known properties, taking into accout the dependencies between the predictions.
We will however focus on message passing neural networks here since they are the most popular model found in literature and have successfully been applied to several different tasks (see also \cref{sec:eval}).

\subsection{Message passing neural network}\label{sec:mpnn}
We explain the concept of message passing neural networks following \citet{gilmer_neural_2017}.
Let $G$ by a directed graph, where edges from $w$ to $v$ have a label represented as $e_{vw}$.
Two nodes can be connected by multiple edges of different kinds.
In the application to source code, each edge kind often has an associated backward edge, allowing information to flow in both directions.
These can just be treated as an additional edge with a label different from the corresponding forward edge.

Message passing neural networks start by assigning an initial hidden state $h^0_v$ to each node $v$ in the graph.
The initial state is usually computed as an embedding of the features of the node.
At every timestep, the network then computes a message for each edge using the \textit{message function} $M$.
The messages of all edges with the same target are aggregated by an \textit{aggregation function} $h$.
This is a slight generalization of the original formulation, where $h$ is always the sum of all incoming messages.
The aggregated messages are then used to update the node hidden state, using the \textit{update function} $U$ for the node.
The following two equations describe this process:

\begin{align}
  m^{t+1}_{v} & = h(\{M(h^{t}_{v},h^{t}_{w},e_{vw}) | w \in N(v)\}) \label{eq:msg} \\
  h^{t+1}_{v} & = U(h^{t}_{v}, m^{t+1}) \label{eq:update}
\end{align}

where $N(v)$ is the set of all nodes $w$ for which there is an edge from $w$ to $v$.
The steps are repeated for $T$ timesteps. Finally, the overall prediction is computed by applying the readout function to the final hidden states $\{h^{T}_{v}\}$ of all nodes:

\begin{align}
  \hat{y} &= R(\{h^{T}_{v} | v \in G\}) \label{eq:readout}
\end{align}

In this computation $M$, $U$ and $R$ are all learnable differentiable functions.
Because the whole system is differentiable, parameters can be learned with gradient-based optimization.

\subsection{Applications to source code}\label{sec:app}
\Cref{tbl:mpnn-applications} shows some applications of (variations of) message passing neural networks to source code.
We will first look at different representations of source code as a graph.
Then, we describe the concrete variant of message passing neural network used in these applications.

\begin{table*}[t]
  \begin{minipage}{\textwidth}
    \begin{tabularx}{\textwidth}{lXX}
      \toprule
      Reference                              & Graph & Task \\ \midrule
      \citet{allamanis_learning_2018}        & enriched AST & \textsc{VarNaming}, \textsc{VarMisuse} \\
      \citet{allamanis_typilus_2020}         & enriched AST  & predict python type annotations \\
      \citet{brauckmann_compiler-based_2020} & enriched AST, CDFG+calls+mem & OpenCL device mapping, OpenCL thread corsening \\
      \citet{cummins_programl_2020}          & IR graph + control-, data- and call-flow & graph algorithms, device mapping, algorithm classification \\
      \citet{fernandes_structured_2020}      & enriched AST & \textsc{MethodNaming}, \textsc{MethodDoc} \\
      \citet{hellendoorn_are_2019}           & enriched AST & checking if extracted invariants are valid \\
      \citet{hellendoorn_global_2019}        & enriched AST & \textsc{VarMisuse} \\
      \citet{li_using_2019}                  & enriched AST & predict log level for log statements \\
      \citet{schrouff_inferring_2019}        & AST + reference/traverse & predict javascript type annotations \\
      \citet{si_learning_2018}               & SSA-CFG with AST + variable-linking & embed semantics for loop invariant prediction \\
      \citet{wei_lambdanet_2020}             & type variables with relationships & predict python type annotations \\
      \bottomrule
    \end{tabularx}
  \end{minipage}

  \caption{Different applications of message passing neural networks to source code tasks}\label{tbl:mpnn-applications}
\end{table*}

\subsubsection{AST representations}
A syntatic way to represent source code as a graph is the form of an abstract syntax tree (AST).
This representation was first introduced by \citet{allamanis_learning_2018} and many further works are based on variations \cite{allamanis_typilus_2020,brauckmann_compiler-based_2020,fernandes_structured_2020,hellendoorn_global_2019,hellendoorn_are_2019,li_using_2019,schrouff_inferring_2019}.
Semantic information is added to the AST in the form of additional edge types.
An overview of the edge types found in these works is given in \cref{tbl:ast-edges}.
These edges add data flow and control flow information for variables to the graph.
Since in practice the message passing network only uses a small number of timesteps, these additional edges are useful to capture dependencies that can potentially be far away in the graph.
Allamanis et al.\ found that these semantic edges greatly increase the performance.
\citet{schrouff_inferring_2019} also use an AST representation, but group their 96 relationship types into only two categories: AST relation like child/parent and reference/traverse which are a kind of semantic edge.

Because each edge type requires its own parameters for the message generation step of the model, restricting the edge types can improve training time.
Which edges are useful however depends on the task.
In an ablation study, \citet{allamanis_learning_2018} found that restricting the edges to semantic edges (removing \textsc{NextToken} and \textsc{Child} edges) affected the performance on the \textsc{VarMisuse} task much more than for the \textsc{VarNaming} task.

\begin{table*}[t]
  \begin{tabularx}{\textwidth}{lXl}
    \toprule
    Edge & Edge between \ldots \\
    \midrule
    \textsc{NextToken} & two consecutive token nodes or sub-token nodes  \\
    \textsc{InToken} & sub-tokens and the AST token node \\
    \textsc{NextLexicalUse} & lexical uses of the same variable (independent of data flow) \\
    \textsc{Child} & AST syntax nodes and their children \\
    \textsc{NextMayUse} & variable tokens and next potential uses of that variable \\
    \textsc{AssignedFrom} & left hand side of an assignment and right hand side \\
    \textsc{ComputedFrom} & variable appearing in the LHS of an assignment and all variables appearing in the RHS\\
    \textsc{OccurrenceOf} & tokens referencing a symbol and nodes that bind this symbol \\
    \textsc{FormalArgName} & arguments in method calls and formal parameters in the signature \\
    \textsc{LastWrite} & syntax node at which a variable was written to and variable token \\
    \textsc{LastRead} & syntax node at which a variable was read from and variable token \\
    \textsc{ReturnsTo} & return token and the method declaration \\
    \textsc{GuardedBy} & variable to enclosing guard expression that must be true for this statement to be executed and uses this variable \\
    \textsc{GuardedByNegation} & variable to enclosing guard expression that must be false for this statement to be executed and uses this variable \\
    \bottomrule
  \end{tabularx}
  \caption{Edge types used to enrich AST graphs}\label{tbl:ast-edges}
\end{table*}

\subsubsection{CFG representations}
AST representations include information about syntax that may not be relevant for semantics, such as dead code.
By basing their representation on a ontrol flow graph (CFG), CFG representations eliminate some of this ``noise''.
The tradeoff is that some of the superfluous information might still communicate useful information.
For example, the order of statements in a control flow graph will be different to the source order, so this information can no longer be used by the model.
\citet{brauckmann_compiler-based_2020} compare both representations on the same tasks and find that there is no single best representation.
They base their graph on a CFG extracted from the LLVM intermediate representation, so the nodes in the graph are LLVM IR instructions.
A similar approach is followed by \citet{cummins_programl_2020}.
They also construct a control flow graph and enrich it with data flow and call flow.
In contrast to the work of Brauckmann et al.\, they include edge positions which differentiate the first operand/branch target from the second and so on.
But nodes do not always need to be IR statements in a CFG representation.
\citet{si_learning_2018} describe a variant where they first construct a control flow graph over statements over the SSA (static single assignment) form but then use the AST representation of each statement as nodes.
Since the SSA form splits a single variable in potentially many differently named ones, they introduce variable linking which connects all instances of a single variable to a node named after the original name.

\subsubsection{Application-specific graphs}
A third possibility to represent programs as graphs is shown by \citet{wei_lambdanet_2020}.
They construct a type inference graph, which only contains predicates believed to be relevant for the type inference problem, such as subtype and usage edges.
Nodes in their graph represent types that are known or need to be assigned.
In contrast to the previous representation methods, this requires more thought about which edges to include for a given application and is thus a less general method.

\subsubsection{Propagation models}
Most of the applications listed in \cref{tbl:mpnn-applications} are based on a special kind of message passing neural network named Gated Graph Neural Network (GGNN)~\cite{li_gated_2017}.
These networks use a simple linear layer on the source node as the message function (with different trainable parameters for each edge kind) and the gated recurrent unit (GRU)~\cite{cho_properties_2014} as the node update function.
For message aggregation, GGNNs sum all messages arriving at a single node.

There are only two models that are not based on the GGNN variant.
\citet{wei_lambdanet_2020} use a different model where they define specialized learnable message functions for each of their edge types.
Since their graph is a hypergraph, they specify how to generate messages for each argument of a hyperedge.
The specialized message functions are mostly based on multilayer feedforward networks.
For aggregation and updating, they use a variant of the attentation based aggregation operator proposed in graph attentation networks~\cite{velickovic_graph_2018}.

\citet{si_learning_2018} also use a linear function to compute messages for each edges.
Messages are aggregated separately for each edge type by summing and applying a nonlinear activation function.
The update is performed by transforming each aggregated result by a linear function followed by a nonlinear activation function.
Interesting to note here is that the update function is not based on the hidden state of the current node.
This means that the model cannot directly propagate information from a node to itself in one step.

The remaining models either use the GGNN model directly \cite{allamanis_learning_2018,brauckmann_compiler-based_2020,fernandes_structured_2020,hellendoorn_are_2019,hellendoorn_global_2019,li_using_2019,schrouff_inferring_2019} or apply slight changes to the message or aggregation function.
All models use the GRU unit as update function.
For type prediction, \citet{allamanis_typilus_2020} use the elementwise maximum instead of sum for aggregation, as it lead to better results.
Intuitively, the elementwise maximum corresponds to a meet-like operation on a lattice defined over $\mathbb{R}^{N}$.
\citet{cummins_programl_2020} change the message function to add a sinusodial positional encoding of the edge position to the hidden state of the source node before applying a linear function.
All other models in \cref{tbl:mpnn-applications} use GGNN unmodified.

\subsubsection{Initial node embedding and readout}
Before message propagation, an initial node embedding must be computed for all nodes in the graph.
These initial node embeddings are commonly computed from a set of features of the nodes.
For AST representations, these features include the ast node type (corresponding to the grammar symbol represented by this node), node properties (a BinaryExpression ast node might have a node property specifying the operator) and node value (for literal and terminal nodes)~\cite{allamanis_learning_2018,schrouff_inferring_2019,brauckmann_compiler-based_2020}.
In statically typed languages, it is also possible to include types of variables as features~\cite{allamanis_learning_2018}.
All features are then converted to vectors using an embedding layer.
For the terminal AST nodes which correspond the the source code tokens, an alternative is to use embeddings generated by a sequence neural network over the original token sequence.
This approach is followed by \citet{fernandes_structured_2020} and \citet{hellendoorn_global_2019}.
For graphs containing IR instructions, the space of possible node values is large due to the possible operand values.
\citet{cummins_programl_2020} therefore construct the embedding by applying an embedding layer to the normalized instruction using using inst2vec~\cite{ben-nun_neural_2018}.

After message propagation, the resulting graph needs to be interpreted in the context of the concrete application.
Predictions about properties of single nodes can directly be computed from the hidden state of that node~\cite{li_using_2019,allamanis_typilus_2020}.
To compute a graph-level vector, a weighted average of a projection of each hidden state can be computed \cite{brauckmann_compiler-based_2020,fernandes_structured_2020}.
Both the weight (attention) and the projection are learnable functions that take the hidden state and in some variants~\cite{cummins_programl_2020} also the initial embedding of the node as an input.
\citet{fernandes_structured_2020} combine this graph vector with the sequence embedding by another linear layer.
Instead of computing the average over all nodes of the graph, \citet{hellendoorn_are_2019} only average the nodes that appear in the invariant.
A similar approach is followed by \citet{allamanis_learning_2018}, where they average over all nodes corresponding the slots of the variable whose name they want to predict.
\citet{si_learning_2018} keep all embeddings as external memory which can be queried by another model through an attention-based mechanism.

\section{Behaviour-based model}
Behaviour-based models make inferences about properties of source code by learning from data gathered from its runtime behaviour.
They provide an interesting alternative to the graph-based models in applications that focus on how the code behaves (semantics) instead of how it was written (syntax).
These models should therefore be more resistant to syntactic modifications.
Some applications of execution-based program features are shown in \cref{tab:app-behaviour}.

A behaviour-based model of a program works by learning features from the executions of programs.
The first question hence is how to represent these executions.
The most common form here is to consider executions as a sequence of program states, where each program state is represented by a set of variable assignments~\cite{yao_learning_2020,wang_learning_2019,padhi_data-driven_2016,piech_learning_2015,paasen_execution_2016}.
Since such trace data contains a lot of unique states, \citet{henkel_code_2018} suggest abstracting the trace to only include a subset of relevant information represented as symbolic events.
Events include for example function calls, function returns, equivalence of return values and function parameters.
Symbolic traces are also used in the model of \citet{wang_learning_2019-1} in combination to the concrete traces.
This is an improvement to prior work by the same authors~\cite{wang_learning_2019} which only used concrete traces.
Instead of simple vectors of program variables, we can also represent the program state as a graph.
It is useful if the underlying programming language supports references or pointers, where variables or memory locations can naturally ``point'' to other locations in the program state.
This representation is used by \citet{brockschmidt_learning_2017} and \citet{li_gated_2017} in a system that learns a heuristic to generate predicates in separation logic that describe invariants of data structures on the program heap (a problem named shape analysis).
Whereas the former work uses simple manually extracted features from the graph, \citet{li_gated_2017} use the gated graph neural networks described in the previous section to automatically learn features for this task.

There are two fundamentally different approaches to apply machine learning to the data extracted from program executions.
The first variant is to train a single embedding or model on executions of different programs.
This is then later applied to new unseen programs.
Almost all the listed works in \cref{tab:app-behaviour} follow this approach, except two.
\citet{yao_learning_2020} train a model to capture the behaviour of a single program, and then extract a loop invariant from the parameters of this model.
A combination between both approaches (learning a shared model for all possible executions and representing a single program by an optimized model) is described by \citet{piech_learning_2015}.
They learn an encoder from the program state into a new space where the training programs can approximately be described as linear functions.
Using these linear functions as features of programs, they then train a classifier that can predict whether feedback given to one program can be propagated to a program by a different student.
Both these applications make use of the fact that machine learning models are often good generic function approximators.
The approach has similarities to the field of program synthesis, especially the task of inferring a program or formula that satisfies certain input output examples.

Compared to graph-based models, there appear to be less works that use executions as a feature for learning over programs, especially ones using deep learning methods.
Reasons for this may be that it is harder to gather execution data since it requires running the program which is impossible in some situations (such as incomplete programs during development, although this can be mitigated slightly by symbolic techniques which can execute single functions) and must be implemented separately for each supported programming language.
That makes this approach more complex to implement compared to the graph-based one.
Main applications include the use in tutoring systems to give feedback to students~\cite{piech_learning_2015,paasen_execution_2016} and inferring invariants~\cite{yao_learning_2020,padhi_data-driven_2016,brockschmidt_learning_2017}.
Intelligent tutoring systems often contain a very controlled programming environment, sidestepping some of the issues associated with gathering execution traces.

\begin{table*}[t]
  \begin{tabularx}{\textwidth}{lX}
    \toprule
    Reference & Description \\
    \midrule
    \citet{yao_learning_2020} & extract non-linear loop invariants from learned model of loop behaviour \\
    \citet{henkel_code_2018} & generate function vectors from usage contexts \\
    \citet{wang_learning_2019} & learn representation of program semantics from execution trace \\
    \citet{padhi_data-driven_2016} & learn preconditions from program traces \\
    \citet{li_gated_2017} & learn separation logic formulas for heap objects \\
    \citet{brockschmidt_learning_2017} & learning shape analysis \\
    \citet{piech_learning_2015} & learn program embedding to propagate student feedback \\
    \citet{paasen_execution_2016} & identify algorithm, errors and error location for student feedback \\
    \bottomrule
  \end{tabularx}
  \caption{Application using runtime features of program executions}\label{tab:app-behaviour}
\end{table*}

\begin{figure}

\end{figure}


\section{Evaluation}\label{sec:eval}

We have seen two different approaches to capture the meaning of source code with machine learning.
In this section, we attempt to look at how well these two approaches perform.
Unfortunately, comparision between the different architectures is difficult, since they are often applied to different tasks.
Even when the tasks are similar (for example, both models applied to infer types), sometimes the results are not comparable because they are evaluated on different datasets.
These factors prevent a clear comparision.
This issue has been noted before by \citet[p. 71]{bourgeois_learning_2019}.
Therefore, we instead will look at the results for some specific tasks were we find some overlap between different papers and note interesting observations and research questions for each task where applicable.

\subsection{Method naming/classification}
In this category, we look at models solving the task of assigning a set of labels or names to methods.
We consider two slightly different tasks: \textsc{MethodNaming} and program classification.
\textsc{MethodNaming} requires the model to predict the name of a method from its body.
This task is often used to evaluated the accurracy of embeddings, since gathering data for it is easy (take a dataset with methods and remove the names) and the name of a method provides a succint description of its meaning.
Program classification is a related task that instead requires classifying short programs according to the implemented algorithm or solved task.
The implementations for both tasks considered in this section are shown in \cref{tab:app-method-summarization}.
Only results relevant to the comparision between graph and behavioural approaches are shown.

A baseline for \textsc{MethodNaming} is given by a non-graph based model by \citet{alon_code2seq_2019}.
They train a model that learns to embed and aggregate paths through the AST of the method automatically.
In contrast to their previous code2vec~\cite{alon_code2vec_2019} model, code2seq uses a sequence based decoder based on this embedding.
The model is evaluated on a dataset of 11 large java projects (java-small \cite{allamanis_convolutional_2016}) and two new datasets consisting of top-starred java projects from GitHub (java-medium, java-large).
\citet{fernandes_structured_2020} improve on this result by using graph neural networks for the encoding step.
Their best result is a combination of a gated graph neural network combined with sequence neural networks for encoding, combined with a new decoder (an LSTM network with a pointer network-style copying mechanism).
An interesting result for this comparision is that they find networks augmented with graph neural networks to outperform baseline methods which do not use any graph networks.
There is also one implementation of a technique based on concrete and symbolic execution traces for the method naming tasks by \citet{wang_learning_2019-1}.
However, the authors evaluate their model on a different dataset, so comparision to state of the art is difficult.
The motiviation they give for using their own dataset is that it is more complex by using algorithmically focused methods from company interviews, in contrast to the java dataset which contains a lot of simple functions such as getters and setters.
They retrain code2seq for this dataset, reporting lower results, which suggests the hypothesis that the dataset is more complex.
It would be interesting to see how the model by \citet{fernandes_structured_2020} performs in comparision on this dataset, and how well their model performs on the java-small and java-large datasets.

The \textsc{LiGeR} model is an extension that adds support for symbolic traces to an earlier model called \textsc{DyPro} by the same authors which was also behaviour-based.
Both of these models have also been tested for the challenge of program classification, which is a more natural task for behaviour based models due to being inherently tied to the semantics of the program.
The evaluations for this model are based on a custom dataset known as \textsc{CoSet}~\cite{wang_coset_2019} which consists of hand-labelled programs from an online coding competition.
The results show that the behaviour-based methods (\textsc{DyPro}, \textsc{LiGeR}) significantly outperform the gated graph neural network variant.
However, the exact AST graph representation used for the GGNN variant was left unspecified in this evaluation.
That the graph representation matters is shown by \citet{cummins_programl_2020}.
Their graph representation is flow, position and value sensitive, and in the evaluation they show that this graph representation leads to improved classification rates using a GGNN on the POJ-104 dataset.
The POJ-104 dataset contains implementations of 104 different algorithms submitted to a judge system.
They compare their result to prior work by \citet{ben-nun_neural_2018} which didn't use graph neural networks and also used a graph representation that did not preserve the node positional order.
This shows that the learning from structure that graph neural networks provide is useful.
The question that remains is how well the \textsc{LiGeR} approach would perform on this dataset.

In summary, we can observe that graph-based representations provide useful signal for both tasks, improving over prior sequence based implementations.
There are some indications that behavioural approaches might have an advantage when the dataset contains many algorithmic-heavy functions but a direct comparision is not possible due to different implementations and datasets.

\begin{table*}[t]
  \begin{tabularx}{\textwidth}{p{10em}lp{12em}X}
    \toprule
    Reference                                  & Task (Metric) & Dataset & Results (\textit{model} score) \\
    \midrule
    code2seq~\cite{alon_code2seq_2019}         & \textsc{MethodNaming} (F1)
      & java-small & \textit{code2vec} 18.62\newline \textit{code2seq} 43.02\newline \textit{TreeLSTM} 35.46 \\
    code2seq~\cite{alon_code2seq_2019}         & \textsc{MethodNaming} (F1)
      & java-large & \textit{code2vec} 42.73\newline \textit{code2seq} 59.19\newline \textit{TreeLSTM} 53.63 \\
   structured neural \newline summarization~\cite{fernandes_structured_2020} & \textsc{MethodNaming} (F1) & java-small & \textit{\textsc{BiLSTM+GNN $\to$ LSTM+POINTER}} 51.4 \textit{code2seq} 43.0 \\
   \textsc{LiGeR}~\cite{wang_learning_2019-1} & \textsc{MethodNaming} (F1) & named methods from algorithmic focused company interviews &  \textit{code2seq} 0.39 \textit{\textsc{LiGer}} 0.57 \\
   \textsc{LiGeR}~\cite{wang_learning_2019-1} & program classification (F1) & \textsc{CoSet}~\cite{wang_coset_2019} &  \textit{code2vec} 0.68 \textit{GGNN} 0.70 \newline \textit{\textsc{DyPro}} 0.81 \textit{\textsc{LiGer}} 0.85 \\
    \textsc{DyPro}~\cite{wang_learning_2019}   & program classification (F1) & handpicked problems from popular online coding platforms & \textit{TreeLSTM} 0.61 \textit{GGNN} 0.66 \textit{\textsc{DyPro}} 0.78 \\
    NCC~\cite{ben-nun_neural_2018} & program classification (accurracy) & POJ-104 & \textit{NCC} 94.83 \textit{TBCNN} 94.0 \\
    \textsc{ProGraML} & program classification (accurracy) & POJ-104 & \textit{NCC} 94.83\newline \textit{XFG-GGNN} 95.71\newline \textit{GGNN-s} 96.13 \textit{GGNN} 96.22 \newline \textit{Transformer} 96.67 \\
    \bottomrule
  \end{tabularx}
  \caption{Implementations for method summarization/classification}\label{tab:app-method-summarization}
\end{table*}

\subsection{Invariant inference}
Invariant inference is a task from program verification.
An invariant is a property that is preserved by a certain code sequence whenever it is executed.
One use case for invariants is proving statements about loops.
Because the invariant is preserved no matter how many times to loop body is executed, it allows reasoning about the state after the loop without explictly considering the number of iterations.
Automatic loop invariant inference is thus an important problem for program verification.

Because the task requires inferring correct invariants, a natural choice is to apply a formal checker to the candidate invariants predicted by the model.
The checker can also return additional counter examples to improve the prediction.
This iterative process is known as counterexample guided inductive synthesis (CeGIS \cite{solar-lezama_combinatorial_2006}).
This approach is followed by \citet{si_learning_2018}, where they use graph based model to convert the program to a structural external memory.
It then uses this external memory in a reinforcment-based learning process interacting with the formal checker.
The model can solve 106 of 133 benchmark programs compared to 100 solved by the best state of the art algorithm, but only if given a larger timeout than in the original competition.
We can see from this result that graph-based embeddings are useful to predict loop invariants.
They also perform an ablation study with an LSTM instead of the graph neural network, showing that the LSTM-variant can solve 13 fewer instances.
This is supported by work of \citet{hellendoorn_are_2019}, where they use a gated graph neural network to reduce the false positive rate of invariants extracted by the dynamic analysis tool Daikon~\cite{ernst_daikon_2007}.

Behavioural based models should be well suited to this problem, since loop invariants essentially require fitting formulas that hold over all possible runtime traces.
And indeed, as demonstrated by \citet{yao_learning_2020}, fitting a model (gated continous logic networks) to the traces and then extracting the formula from that model can perform well, solving all but 9 of the 133 problems in the benchmark set of \citet{si_learning_2018}.
The remaining 9 problems are claimed to be theoretically unsolvable.

The gated continous logic network by \citet{yao_learning_2020} is trained for each single program separately, learning to represent only the behaviour of that program.
In contrast, \citet{wang_learning_2019} show a different approach where they train a single generic model to embed program traces, and apply this model to the task of verifying whether an invariant for a loop is valid or not.
They evaluate their approach on a dataset generated by formally checking invariants produced from Daikon to obtain positive examples and add negative examples based on mutations of those.
In both accurracy and F1-score, the model beats a similar model trained using a gated graph neural network and one using a TreeLSTM.
They do however simply use the hidden state of the root node of the AST to extract a single embedding from the GGNN, and leave the concrete edges they used in their graph representation of code unspecified.
It would be interesting to see the results for the GGNN for on an enriched AST, where the embedding is extracted by averaging the hidden state of the nodes which are present in the invariant, as in \citet{hellendoorn_are_2019}.

In general, there are still not enough comparable works on predicting loop invariants with different models to reach a definite answer on which model is better.
While both architectures capture enough information to be useful predictors for invariants, they are evaluated in different settings (verifying invariants vs generating) and on different datasets.
A possible future research question could be to evaluate them in a common setting, to obtain insights into how well the different program representations perform.

\section{Conclusion}
We have seen that both graph- and behaviour-based models have their use for learning tasks over source code.
Although they are applied for similar tasks, a direct comparision is often not possible due to different datasets and slightly different applications.
Some future research directions could be:

\paragraph{Can we design a generic benchmark dataset to compare these models on?}
  As seen in the evaluation, models are often evaluated on ad-hoc tasks and benchmark sets.
  It would be good to have a standarised, commonly accepted set of tasks along with datasets to compare different approaches on.
  This could also be helpful in determining if there are generic, pre-trainable models that work well for a wide variety of tasks as is the case for NLP.
\paragraph{What are the weaknesses and strengths of each model?}
  Graph based models can exploit syntatical similarities taking hints from the programmer, which behaviour based models cannot. There are indications that this makes behaviour based models better for complex code that is algorithmic in nature.
  To explore this, a comparision of state of the art models for both tasks on the same dataset is needed.
  An interesting avenue in this direction is also work on adversarial examples, which provide insight into what properties of the input data these model bases their predictions on \cite{zhang_generating_2020,yefet_adversarial_2020,ramakrishnan_semantic_2020,bielik_adversarial_2020}.
\paragraph{Can both models be useful in combination?}
  Related to the previous question, if these models have different strengths, a variant that capitalizes on both models' strength by combining could be explored.

\clearpage

\bibliographystyle{ACM-Reference-Format}
\bibliography{zotero}

\end{document}
